{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIADS 543 Unsupervised Learning (Week 4)\n",
    "# Combining unsupervised and supervised methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are two main classes for label propagation in scikit-learn: LabelPropagation and LabelSpreading. Both of these take the set of input data instances and construct a graph over the full dataset based on a pairwise similarity measure between points. The difference is in (a) how they implement the similarity measure and (b) how they strictly they 'clamp' input labels to specific values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelPropagation is the simpler technique: it does 'hard' clamping of labels to values and does not modify the raw input similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy with full, complete data: 0.9192006950477846\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.semi_supervised import LabelPropagation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# This function takes a dataset and label set as input, and returns the following:\n",
    "#   - The X features of the subset of instances that had intact labels\n",
    "#   - The y labels of the subset of instances that had intact labels\n",
    "#   - The X features of the complete training set\n",
    "#   - The y labels of the complete training set WITH DESTROYED LABELS according to the assignment specifications.\n",
    "#\n",
    "# input parameters frac_0, frac_1 indicate the probability you want to mangle class 0 and class 1 labels\n",
    "# respectively.\n",
    "def get_mangled_label_dataset(X_train, y_train, frac_0, frac_1):\n",
    "    rng = np.random.RandomState(0)\n",
    "\n",
    "    X_train_0 = X_train[y_train == 0]\n",
    "    y_train_0 = y_train[y_train == 0]\n",
    "\n",
    "    X_train_1 = X_train[y_train == 1]\n",
    "    y_train_1 = y_train[y_train == 1]\n",
    "\n",
    "    X_train_complete = np.vstack((X_train_0, X_train_1))\n",
    "    y_train_complete = np.concatenate((y_train_0, y_train_1))\n",
    "\n",
    "    random_unlabeled_points_0 = rng.rand(len(y_train_0)) < frac_0\n",
    "    random_unlabeled_points_1 = rng.rand(len(y_train_1)) < frac_1\n",
    "    random_unlabeled_points = np.concatenate((random_unlabeled_points_0, random_unlabeled_points_1))\n",
    "\n",
    "    random_labeled_points_0 = np.logical_not(random_unlabeled_points_0)\n",
    "    random_labeled_points_1 = np.logical_not(random_unlabeled_points_1)\n",
    "\n",
    "    labeled_subset_X_train_0  = X_train_0[random_labeled_points_0]\n",
    "    labeled_subset_X_train_1  = X_train_1[random_labeled_points_1]\n",
    "    labeled_subset_y_train_0  = y_train_0[random_labeled_points_0]\n",
    "    labeled_subset_y_train_1  = y_train_1[random_labeled_points_1]\n",
    "\n",
    "    labeled_subset_X_train = np.vstack((labeled_subset_X_train_0, labeled_subset_X_train_1))\n",
    "    labeled_subset_y_train = np.concatenate((labeled_subset_y_train_0, labeled_subset_y_train_1))\n",
    "\n",
    "    labels_train_with_destroyed = np.copy(y_train_complete)\n",
    "    labels_train_with_destroyed[random_unlabeled_points] = -1\n",
    "\n",
    "    return (labeled_subset_X_train, labeled_subset_y_train, X_train_complete, labels_train_with_destroyed)\n",
    "\n",
    "df = pd.read_csv(\"./spam.csv\")\n",
    "\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "X_train = StandardScaler().fit_transform(X_train_raw)\n",
    "X_test  = StandardScaler().fit_transform(X_test_raw)\n",
    "\n",
    "# fit a support vector machine to the complete dataset with undestroyed labels\n",
    "svc_full = SVC()\n",
    "\n",
    "svc_full.fit(X_train, y_train)\n",
    "test_preds_full = svc_full.predict(X_test)\n",
    "acc_full = accuracy_score(y_test, test_preds_full)\n",
    "print (\"SVM accuracy with full, complete data:\", acc_full)\n",
    "\n",
    "(labeled_subset_X_train, labeled_subset_y_train, X_train_complete, y_train_complete_missing) = \\\n",
    "     get_mangled_label_dataset(X_train, y_train, 0.05, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy with LabelPropagation inferred labels on complete data: 0.6038227628149435\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelPropagation\n",
    "n_neighbors= 9\n",
    "\n",
    "# In this example, we'll use a k-NN kernel on the graph. It produces a sparse but efficient graph.\n",
    "label_prop_model = LabelPropagation(kernel='knn', n_neighbors=n_neighbors, \n",
    "                                  max_iter=50, tol=0.001)\n",
    "\n",
    "# call fit to build the similarity graph between items\n",
    "label_prop_model.fit(X_train_complete, y_train_complete_missing)\n",
    "\n",
    "# infer the missing labels.\n",
    "pred_y_train_complete = label_prop_model.predict(X_train_complete) \n",
    "\n",
    "# NOTE: instead of the above line, we could have also used the transduction_ property of\n",
    "# the LabelSpreading object, e.g.\n",
    "#\n",
    "#   pred_y_train_complete = label_prop_model.transduction_ \n",
    "#\n",
    "# which stores the label output inferred for the data input to\n",
    "# the fit method.  The predict method can also be used to predict for *new* data.\n",
    "\n",
    "# fit a support vector machine to the complete dataset with inferred labels\n",
    "svc_label_prop = SVC()\n",
    "\n",
    "svc_label_prop.fit(X_train_complete, pred_y_train_complete)\n",
    "test_preds_label_prop = svc_label_prop.predict(X_test)\n",
    "acc_with_label_prop   = accuracy_score(y_test, test_preds_label_prop)\n",
    "print (\"SVM accuracy with LabelPropagation inferred labels on complete data:\", acc_with_label_prop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LabelSpreading is more sophisticated: it does 'soft' clamping of labels to values, allowing them to be modified if the local evidence is strong enough, and computes a modified graph using a smoothed (regularized) form of the similarity matrix. The strictness of the label clamping is controlled by the `alpha` parameter: `alpha = 0` gives hard clamping and higher values of `alpha` relaxes the clamping factor.  The edge weights of the modified graph are normalized using the normalized graph Laplacian matrix, as described in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM accuracy with LabelSpreading inferred labels on complete data: 0.6715899218071243\n"
     ]
    }
   ],
   "source": [
    "from sklearn.semi_supervised import LabelSpreading\n",
    "n_neighbors= 7\n",
    "\n",
    "label_spread_model = LabelSpreading(kernel='knn', n_neighbors=n_neighbors, \n",
    "                                  alpha=0.1, max_iter=50, tol=0.001)\n",
    "label_spread_model.fit(X_train_complete, y_train_complete_missing)\n",
    "pred_y_train_complete = label_spread_model.predict(X_train_complete)\n",
    "\n",
    "# fit a support vector machine to the complete dataset with inferred labels\n",
    "svc_label_spread = SVC()\n",
    "\n",
    "svc_label_spread.fit(X_train_complete, pred_y_train_complete)\n",
    "test_preds_label_spread = svc_label_spread.predict(X_test)\n",
    "acc_with_label_spread   = accuracy_score(y_test, test_preds_label_spread)\n",
    "print (\"SVM accuracy with LabelSpreading inferred labels on complete data:\", acc_with_label_spread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import SimpleImputer, IterativeImputer, KNNImputer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "# Some of the following code was adapted and modified from the scikit-learn impute documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# This function takes a dataset X with labels y as input, and an optional\n",
    "# \"missing rate\" that indicates the proportion of total instances (rows)\n",
    "# that should have at least one missing value. It makes a copy of the input\n",
    "# and returns the modified X, y as output.\n",
    "def create_copy_with_missing_values(X, y, missing_rate = 0.75):\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    n_missing_samples = int(n_samples * missing_rate)\n",
    "    \n",
    "    # now pick which rows, columns should correspond to the missing samples\n",
    "    missing_instances = rng.choice(n_samples, size=n_missing_samples, replace=False)\n",
    "    missing_features  = rng.randint(0, n_features, n_missing_samples)\n",
    "    \n",
    "    X_missing = X.copy()\n",
    "    y_missing = y.copy()\n",
    "\n",
    "    X_missing[missing_instances, missing_features] = np.nan\n",
    "\n",
    "    return X_missing, y_missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's an example that tries out multiple imputation strategies on the\n",
    "# same missing-data scenario.  \n",
    "\n",
    "rng = np.random.RandomState(42)\n",
    "CV_SPLITS = 5\n",
    "missing_rate = 0.95\n",
    "regressor = RandomForestRegressor(random_state=42)\n",
    "x_labels = ['Full data',\n",
    "            'Simple imputation: always zero',\n",
    "            'Simple imputation: mean',\n",
    "            'Simple imputation: median',\n",
    "            'Iterative imputation',\n",
    "            'k-NN imputation',\n",
    "           ]\n",
    "\n",
    "score_type = 'r2'\n",
    "n_entries = len(x_labels)\n",
    "mses_dataset = np.zeros(n_entries)\n",
    "stds_dataset = np.zeros(n_entries)\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "(X_full, y_full) = load_breast_cancer(return_X_y = True)\n",
    "\n",
    "X_missing, y_missing = create_copy_with_missing_values(X_full, y_full, missing_rate = missing_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flagging missing information via connecting\n",
    "# the imputer and regressor using a pipeline object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_using_imputer(regressor, imputer,\n",
    "                           X_missing, y_missing, score_type = score_type):\n",
    "    estimator = make_pipeline(imputer, regressor)\n",
    "    impute_scores = cross_val_score(estimator, X_missing, y_missing,\n",
    "                                    scoring=score_type,\n",
    "                                    cv=CV_SPLITS)\n",
    "    # print(impute_scores)\n",
    "    return impute_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Simple imputation by replacing missing values by zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_zero_score(regressor, X_missing, y_missing):\n",
    "\n",
    "    imputer = SimpleImputer(missing_values=np.nan, add_indicator=True,\n",
    "                            strategy='constant', fill_value=0)\n",
    "    zero_impute_scores = get_scores_using_imputer(regressor, imputer, X_missing, y_missing)\n",
    "    return zero_impute_scores.mean(), zero_impute_scores.std()\n",
    "\n",
    "mses_dataset[0], stds_dataset[0] = get_impute_zero_score(regressor, X_missing, y_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False  True False]\n",
      " [ True False False]\n",
      " [False False False]]\n",
      "[0 2 3]\n"
     ]
    }
   ],
   "source": [
    "# Here's the example of the MissingIndicator class as discussed in this week's lecture.\n",
    "import numpy as np\n",
    "from sklearn.impute import MissingIndicator\n",
    "X1 = np.array([[np.nan, 1, np.nan, 7], \n",
    "               [4, 0, 1., np.nan], \n",
    "               [8, 1, 2., 0]])\n",
    "X2 = np.array([[5, 1, np.nan, -1.], \n",
    "               [np.nan, 2, 3, -3.], \n",
    "               [2, 10., 4, 0]])\n",
    "indicator = MissingIndicator()\n",
    "indicator.fit(X1)\n",
    "X2_tr = indicator.transform(X2)\n",
    "print(X2_tr)\n",
    "print(indicator.features_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple imputatation using column mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_mean(regressor, X_missing, y_missing):\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\",\n",
    "                            add_indicator=True)\n",
    "    mean_impute_scores = get_scores_using_imputer(regressor, imputer, X_missing, y_missing)\n",
    "    return mean_impute_scores.mean(), mean_impute_scores.std()\n",
    "\n",
    "\n",
    "mses_dataset[1], stds_dataset[1] = get_impute_mean(regressor, X_missing, y_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple imputatation using column median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_median(regressor, X_missing, y_missing):\n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy=\"median\",\n",
    "                            add_indicator=True)\n",
    "    mean_impute_scores = get_scores_using_imputer(regressor, imputer, X_missing, y_missing)\n",
    "    return mean_impute_scores.mean(), mean_impute_scores.std()\n",
    "\n",
    "\n",
    "mses_dataset[2], stds_dataset[2] = get_impute_median(regressor, X_missing, y_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_iterative(regressor, X_missing, y_missing):\n",
    "    imputer = IterativeImputer(missing_values=np.nan, add_indicator=True,\n",
    "                               random_state=0, n_nearest_features=5,\n",
    "                               sample_posterior=True)\n",
    "    iterative_impute_scores = get_scores_using_imputer(regressor, imputer,\n",
    "                                                     X_missing,\n",
    "                                                     y_missing)\n",
    "    return iterative_impute_scores.mean(), iterative_impute_scores.std()\n",
    "\n",
    "mses_dataset[3], stds_dataset[3] = get_impute_iterative(regressor, X_missing, y_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Nearest Neighbors imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impute_knn_score(regressor, X_missing, y_missing):\n",
    "    imputer = KNNImputer(missing_values=np.nan, add_indicator=True)\n",
    "    knn_impute_scores = get_scores_using_imputer(regressor, imputer, X_missing, y_missing)\n",
    "    return knn_impute_scores.mean(), knn_impute_scores.std()\n",
    "\n",
    "mses_dataset[4], stds_dataset[4] = get_impute_knn_score(regressor, X_missing, y_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimate the regression task score using the full original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8212601859038916 0.06187398670502936\n"
     ]
    }
   ],
   "source": [
    "def get_full_score(regressor, X, y, score_type = score_type):\n",
    "    full_scores = cross_val_score(regressor, X, y,\n",
    "                                  scoring= score_type,\n",
    "                                  cv=CV_SPLITS)\n",
    "    return full_scores.mean(), full_scores.std()\n",
    "\n",
    "\n",
    "mses_dataset[5], stds_dataset[5] = get_full_score(regressor, X_full, y_full)\n",
    "\n",
    "print (mses_dataset[5], stds_dataset[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Plot results\n",
    "### This plotting code adapted from scikit-learn impute documentation.\n",
    "\n",
    "n_bars = n_entries\n",
    "xval   = np.arange(n_bars)\n",
    "\n",
    "colors = ['r', 'g', 'b', 'orange', 'black', 'yellow']\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax1 = plt.subplot(121)\n",
    "for j in xval:\n",
    "    ax1.barh(j, mses_dataset[j], xerr=stds_dataset[j],\n",
    "             color=colors[j], alpha=0.6, align='center')\n",
    "\n",
    "ax1.set_title('Effect of different imputation methods on regression score')\n",
    "ax1.set_xlim(left=np.min(mses_dataset) * 0.8,\n",
    "             right=np.max(mses_dataset) * 1.1)\n",
    "ax1.set_yticks(xval)\n",
    "ax1.set_xlabel(score_type)\n",
    "ax1.invert_yaxis()\n",
    "ax1.set_yticklabels(x_labels)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
